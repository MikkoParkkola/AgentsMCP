"""
Fixed Working TUI - Addresses indentation bug and connects to real LLM

This provides a working TUI that:
1. Fixes the progressive indentation issue by proper cursor management
2. Connects to the real LLM client for actual conversations
3. Maintains immediate character input feedback
"""

import asyncio
import sys
import os
import signal
import logging
import shutil
from typing import Optional
import termios
import tty

logger = logging.getLogger(__name__)


class FixedWorkingTUI:
    """Fixed TUI that properly manages cursor position and connects to LLM."""
    
    def __init__(self):
        self.running = False
        self.input_buffer = ""
        self.original_settings = None
        self.llm_client = None
        self.cursor_col = 0
        self._configure_tui_logging()
    
    def _configure_tui_logging(self):
        """Configure logging for TUI mode - no console output, file only."""
        try:
            import tempfile
            
            # Configure logging to file only for TUI mode
            log_file = tempfile.gettempdir() + "/agentsmcp_tui_debug.log"
            
            # Configure LLM client logger specifically  
            llm_logger = logging.getLogger('agentsmcp.conversation.llm_client')
            
            # Remove any existing console handlers
            for handler in llm_logger.handlers[:]:
                if isinstance(handler, logging.StreamHandler) and handler.stream == sys.stderr:
                    llm_logger.removeHandler(handler)
            
            # Add file handler only
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(logging.DEBUG)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            llm_logger.addHandler(file_handler)
            
            # Set level to WARNING for console (only errors)
            llm_logger.setLevel(logging.WARNING)
            
            # Also configure main logger to prevent contamination
            main_logger = logging.getLogger('agentsmcp')
            for handler in main_logger.handlers[:]:
                if isinstance(handler, logging.StreamHandler) and handler.stream == sys.stderr:
                    main_logger.removeHandler(handler)
                    
            # Add file handler for main logger too
            main_logger.addHandler(file_handler)
            main_logger.setLevel(logging.WARNING)
            
            logger.info(f"TUI logging configured - debug logs written to {log_file}")
            
        except Exception as e:
            logger.warning(f"Could not configure TUI logging: {e}")
        
    def setup_terminal(self):
        """Setup terminal for immediate character input."""
        if sys.stdin.isatty():
            try:
                # Save original terminal settings
                self.original_settings = termios.tcgetattr(sys.stdin.fileno())
                # Set raw mode for immediate character input
                tty.setraw(sys.stdin.fileno())
                return True
            except Exception as e:
                logger.warning(f"Could not setup terminal: {e}")
                return False
        return False
    
    def restore_terminal(self):
        """Restore original terminal settings."""
        if self.original_settings and sys.stdin.isatty():
            try:
                termios.tcsetattr(sys.stdin.fileno(), termios.TCSADRAIN, self.original_settings)
                sys.stdout.flush()
            except Exception as e:
                logger.warning(f"Could not restore terminal: {e}")
    
    def clear_screen_and_show_prompt(self):
        """Clear screen and draw header at column 0, without leaving stray column offsets.

        Note: We deliberately start each printed line with '\r' to ensure the
        cursor returns to column 0. Some terminals keep the current column when
        processing a bare '\n'. Using '\r\n' (or a leading '\r') prevents the
        progressive indentation artifact.
        """
        sys.stdout.write('\033[2J\033[H')  # Clear screen and move to top-left
        sys.stdout.write('\rüöÄ AgentsMCP - Fixed Working TUI\r\n')
        sys.stdout.write('\r' + '‚îÄ' * 50 + '\r\n')  # Consistent width
        sys.stdout.write('\rType your message (Ctrl+C to exit, /quit to quit):\r\n')
        # Do NOT print the prompt here; leave header drawn at a clean column 0.
        sys.stdout.flush()
        self.cursor_col = 0
    
    def show_prompt(self):
        """Show prompt at beginning of line."""
        sys.stdout.write('\r> ')  # Carriage return to beginning, then prompt
        sys.stdout.flush()
        self.cursor_col = 2  # After "> "
    
    def setup_llm_client(self):
        """Setup LLM client for real conversations."""
        try:
            # Set TUI mode environment variable to prevent console log contamination
            import os
            os.environ['AGENTSMCP_TUI_MODE'] = '1'
            
            # Import LLM client
            sys.path.insert(0, '/Users/mikko/github/AgentsMCP/src')
            from agentsmcp.conversation.llm_client import LLMClient
            
            self.llm_client = LLMClient()
            logger.info(f"LLM client initialized with provider: {self.llm_client.provider}, model: {self.llm_client.model}")
            return True
        except Exception as e:
            logger.error(f"Failed to setup LLM client: {e}")
            return False
    
    async def handle_input(self):
        """Handle keyboard input with immediate echo and proper cursor management."""
        loop = asyncio.get_event_loop()
        
        while self.running:
            try:
                # Read one character (non-blocking)
                if sys.stdin.isatty():
                    char = await loop.run_in_executor(None, sys.stdin.read, 1)
                else:
                    # Fallback for non-TTY
                    line = await loop.run_in_executor(None, input, "> ")
                    await self.process_line(line)
                    continue
                
                # Handle special characters
                if ord(char) == 3:  # Ctrl+C
                    break
                elif ord(char) == 13 or ord(char) == 10:  # Enter
                    sys.stdout.write('\r\n')
                    await self.process_line(self.input_buffer)
                    self.input_buffer = ""
                    self.show_prompt()
                elif ord(char) == 127 or ord(char) == 8:  # Backspace
                    if self.input_buffer and self.cursor_col > 2:
                        self.input_buffer = self.input_buffer[:-1]
                        sys.stdout.write('\b \b')  # Move back, write space, move back
                        self.cursor_col -= 1
                elif ord(char) >= 32:  # Printable characters
                    self.input_buffer += char
                    sys.stdout.write(char)  # IMMEDIATE ECHO
                    self.cursor_col += 1
                
                sys.stdout.flush()
                
            except Exception as e:
                logger.error(f"Error in input handling: {e}")
                break
    
    async def process_line(self, line: str):
        """Process a complete line of input and send to LLM."""
        line = line.strip()
        # Built-in commands
        if line.lower() == '/agents':
            try:
                from ...runtime_config import Config
                cfg = Config.load()
                sys.stdout.write('
Configured agents:
')
                for name, ac in cfg.agents.items():
                    prov = getattr(ac.provider, 'value', str(ac.provider))
                    sys.stdout.write(f"- {name}: provider={prov} model={ac.model}
")
                sys.stdout.flush()
            except Exception as e:
                sys.stdout.write(f"Error reading config: {e}
")
            self.show_prompt()
            return
        if line.lower() in ['/quit', '/exit', 'quit', 'exit']:
            self.running = False
            sys.stdout.write('
üëã Goodbye!
')
            return
        if line.lower() == '/help':
            sys.stdout.write('
üìö Commands:
')
            sys.stdout.write('  /help   - Show this help
')
            sys.stdout.write('  /quit   - Exit TUI
')
            sys.stdout.write('  /clear  - Clear conversation history
')
            sys.stdout.write('  /agents - List configured agents
')
            sys.stdout.write('  Ctrl+C  - Exit TUI
')
            sys.stdout.write('
üí¨ Just type normally to chat with the LLM!
')
            return
        if line.lower() == '/clear':
            if self.llm_client:
                self.llm_client.clear_history()
                sys.stdout.write('
üßπ Conversation history cleared!
')
            else:
                sys.stdout.write('
‚ö†Ô∏è  LLM client not available
')
            return
        if not line:
            return
        # Thinking indicator
        sys.stdout.write('
ü§î Thinking...
')
        sys.stdout.flush()
        try:
            if self.llm_client:
                from ...orchestration.team_runner import run_team, DEFAULT_TEAM
                cols, _ = shutil.get_terminal_size(fallback=(100, 40))
                sys.stdout.write('üö© Orchestrating team: ' + ', '.join(DEFAULT_TEAM) + '
')
                sys.stdout.flush()
                async def progress(ev, data):
                    t = data.get('time','')
                    agent = data.get('agent','')
                    if ev.endswith('spawned'):
                        msg = f"[{t}] ‚ñ∂ {agent} started"
                    elif ev.endswith('completed'):
                        msg = f"[{t}] ‚úÖ {agent} completed"
                    else:
                        msg = f"[{t}] {ev} {agent}"
                    sys.stdout.write('' + msg + '
')
                    sys.stdout.flush()
                results = await run_team(line, DEFAULT_TEAM, progress_callback=progress)
                from .ansi_markdown_processor import render_markdown_lines
                safe_width = max(20, cols - 2)
                for role, out in results.items():
                    sys.stdout.write(f'üß© {role}:
')
                    try:
                        for ln in render_markdown_lines(out or '(no output)', width=safe_width, indent=''):
                            sys.stdout.write('' + ln + '
')
                    except Exception:
                        for ln in (out or '(no output)').split('
'):
                            sys.stdout.write('' + ln + '
')
            else:
                sys.stdout.write(f"‚ö†Ô∏è  LLM client unavailable. You said: "{line}"
")
                sys.stdout.write('   Try restarting the TUI to reconnect.
')
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            sys.stdout.write(f"‚ùå Error: {str(e)}
")
            sys.stdout.write('   Please try again or use /help for commands.
')
        sys.stdout.flush()

    async def run(self):
        """Run the fixed working TUI."""
        self.running = True
        
        # Setup signal handlers
        def signal_handler(signum, frame):
            self.running = False
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # Setup LLM client
        llm_ready = self.setup_llm_client()
        if not llm_ready:
            sys.stdout.write('‚ö†Ô∏è  Warning: LLM client failed to initialize. Chat may not work properly.\n')
            sys.stdout.write('   Continuing in demo mode...\n')
        
        # Setup terminal
        terminal_setup = self.setup_terminal()
        
        try:
            self.clear_screen_and_show_prompt()
            
            if llm_ready:
                # Show connection status on its own line at column 0
                sys.stdout.write(f"\r‚úÖ Connected to {self.llm_client.provider} - {self.llm_client.model}\r\n")
            # Always show the prompt after header + status
            self.show_prompt()
            
            await self.handle_input()
        
        except KeyboardInterrupt:
            sys.stdout.write('\nüëã Goodbye!\n')
        
        finally:
            if terminal_setup:
                self.restore_terminal()
    
    def __del__(self):
        """Ensure terminal is restored on cleanup."""
        if hasattr(self, 'original_settings') and self.original_settings:
            self.restore_terminal()


async def launch_fixed_working_tui():
    """Launch the fixed working TUI with real LLM connection."""
    tui = FixedWorkingTUI()
    await tui.run()
    return 0


if __name__ == "__main__":
    # Direct execution support
    asyncio.run(launch_fixed_working_tui())
